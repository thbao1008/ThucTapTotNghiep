import React, { useState, useEffect, useRef } from "react";
import AudioRecorder from "../common/AudioRecorder";
import api from "../../api";
import { FaMicrophone } from "react-icons/fa";
import "../../styles/speaking-practice.css";

export default function SpeakingRound({
  sessionId,
  roundNumber,
  level,
  onSave,
  onCancel
}) {
  const [prompt, setPrompt] = useState("");
  const [timeLimit, setTimeLimit] = useState(30);
  const [timeRemaining, setTimeRemaining] = useState(timeLimit);
  const [progressAnimationKey, setProgressAnimationKey] = useState(0); // Key ƒë·ªÉ restart animation
  const timeRemainingRef = useRef(timeLimit); // Ref ƒë·ªÉ track timeRemaining cho progress
  const [isRecording, setIsRecording] = useState(false);
  const [audioBlob, setAudioBlob] = useState(null);
  const [submitting, setSubmitting] = useState(false);
  const [wordTooltip, setWordTooltip] = useState(null);
  const [openWordTooltip, setOpenWordTooltip] = useState(null); // Word ƒëang m·ªü tooltip
  const [wordDefinitionsCache, setWordDefinitionsCache] = useState(() => {
    // Load cache t·ª´ localStorage khi component mount
    try {
      const cached = localStorage.getItem('wordDefinitionsCache');
      return cached ? JSON.parse(cached) : {};
    } catch {
      return {};
    }
  });
  const [loadingWords, setLoadingWords] = useState({}); // Loading state cho t·ª´ng t·ª´
  const [preloadingWords, setPreloadingWords] = useState(false); // ƒêang preload t·ª´
  const [countdown, setCountdown] = useState(null);
  const [showPrompt, setShowPrompt] = useState(false); // Ch·ªâ hi·ªÉn th·ªã prompt sau countdown
  const [webSpeechTranscript, setWebSpeechTranscript] = useState("");
  const [webSpeechHighlights, setWebSpeechHighlights] = useState(new Set()); // T·ª´ ƒë√£ ƒë∆∞·ª£c n√≥i ƒë√∫ng
  const [highlightedWords, setHighlightedWords] = useState(new Set()); // Real-time highlights t·ª´ Web Speech
  const [missingWords, setMissingWords] = useState(new Set()); // T·ª´ kh√¥ng n√≥i ƒë∆∞·ª£c (sau khi ki·ªÉm tra)
  const [loadingPrompt, setLoadingPrompt] = useState(true); // Loading state cho prompt
  const [promptError, setPromptError] = useState(null); // Error state cho prompt
  const timerRef = useRef(null);
  const countdownRef = useRef(null);
  const startTimeRef = useRef(null);
  const audioRecorderRef = useRef(null);
  const promptDataRef = useRef(null); // L∆∞u prompt data ƒë·ªÉ hi·ªÉn th·ªã sau
  const recognitionRef = useRef(null); // Web Speech API recognition
  const isRecordingRef = useRef(false); // Ref ƒë·ªÉ track recording state
  const mediaRecorderRef = useRef(null); // MediaRecorder instance
  const mediaStreamRef = useRef(null); // MediaStream from getUserMedia
  const audioChunksRef = useRef([]); // Audio chunks for MediaRecorder
  const progressIntervalRef = useRef(null); // Ref cho progress interval

  // L·∫•y prompt t·ª´ backend v√† t·ª± ƒë·ªông b·∫Øt ƒë·∫ßu
  useEffect(() => {
    setLoadingPrompt(true);
    setPromptError(null);
    fetchPrompt();
  }, [sessionId, roundNumber, level]);
  
  // Auto-start sau khi prompt ƒë∆∞·ª£c load
  useEffect(() => {
    if (promptDataRef.current && !isRecording && !showPrompt && !loadingPrompt && !promptError) {
      const autoStartTimer = setTimeout(() => {
        if (promptDataRef.current && !isRecording) {
          startRecording();
        }
      }, 500); // ƒê·ª£i m·ªôt ch√∫t ƒë·ªÉ prompt data ƒë∆∞·ª£c set
      
      return () => clearTimeout(autoStartTimer);
    }
  }, [loadingPrompt, promptError, isRecording, showPrompt]);

  // B·ªè countdown - kh√¥ng c·∫ßn n·ªØa v√¨ t·ª± ƒë·ªông b·∫Øt ƒë·∫ßu

  // Timer countdown khi ƒëang ghi √¢m
  useEffect(() => {
    if (isRecording && timeRemaining > 0) {
      timerRef.current = setInterval(() => {
        setTimeRemaining((prev) => {
          const newValue = prev <= 1 ? 0 : prev - 1;
          timeRemainingRef.current = newValue;
          if (prev <= 1) {
            // Khi h·∫øt th·ªùi gian, ƒë√°nh d·∫•u ƒë·ªÉ submit sau khi audio ƒë∆∞·ª£c t·∫°o
            finishEarlyRef.current = true;
            stopRecording();
          }
          return newValue;
        });
      }, 1000);
      
      // Trigger CSS animation b·∫±ng c√°ch thay ƒë·ªïi key
      setProgressAnimationKey(prev => prev + 1);
    } else {
      if (timerRef.current) {
        clearInterval(timerRef.current);
        timerRef.current = null;
      }
      if (progressIntervalRef.current) {
        clearInterval(progressIntervalRef.current);
        progressIntervalRef.current = null;
      }
      setProgressAnimationKey(0);
    }

    return () => {
      if (timerRef.current) {
        clearInterval(timerRef.current);
      }
      if (progressIntervalRef.current) {
        clearInterval(progressIntervalRef.current);
      }
    };
  }, [isRecording, timeLimit]);

  // B·ªè auto-submit khi highlight h·∫øt - kh√¥ng highlight n·ªØa n√™n kh√¥ng c·∫ßn

  const fetchPrompt = async () => {
    try {
      setLoadingPrompt(true);
      setPromptError(null);
      
      const res = await api.get(
        `/learners/speaking-practice/sessions/${sessionId}/prompt`,
        { params: { round: roundNumber, level } }
      );
      
      if (!res.data || !res.data.prompt) {
        throw new Error("Kh√¥ng nh·∫≠n ƒë∆∞·ª£c prompt t·ª´ server");
      }
      
      // L∆∞u prompt data nh∆∞ng ch∆∞a hi·ªÉn th·ªã
      promptDataRef.current = {
        prompt: res.data.prompt,
        timeLimit: res.data.time_limit || 30
      };
      setTimeLimit(res.data.time_limit || 30);
      // Reset c√°c state khi fetch prompt m·ªõi
      setPrompt("");
      setShowPrompt(false);
      setAudioBlob(null);
      setSubmitting(false);
      setIsRecording(false);
      isRecordingRef.current = false;
      setHighlightedWords(new Set());
      setWebSpeechHighlights(new Set()); // Reset Web Speech highlights
      setTimeRemaining(res.data.time_limit || 30);
      setCountdown(null); // Reset countdown
      setLoadingPrompt(false);
      
      // Pre-fetch t·∫•t c·∫£ t·ª´ trong prompt ngay khi load
      if (res.data.prompt) {
        preloadWordDefinitions(res.data.prompt);
      }
    } catch (err) {
      console.error("‚ùå Error fetching prompt:", err);
      setPromptError(err?.response?.data?.message || err?.message || "Kh√¥ng th·ªÉ t·∫£i ƒë·ªÅ b√†i. Vui l√≤ng th·ª≠ l·∫°i.");
      setLoadingPrompt(false);
      
      // Retry sau 2 gi√¢y
      setTimeout(() => {
        fetchPrompt();
      }, 2000);
    }
  };

  // B·ªè startCountdown - kh√¥ng c·∫ßn n·ªØa v√¨ t·ª± ƒë·ªông b·∫Øt ƒë·∫ßu

  const startRecording = () => {
    // Hi·ªÉn th·ªã prompt v√† b·∫Øt ƒë·∫ßu ghi √¢m
    if (promptDataRef.current) {
      const promptText = promptDataRef.current.prompt;
      setPrompt(promptText);
      setTimeLimit(promptDataRef.current.timeLimit);
      setTimeRemaining(promptDataRef.current.timeLimit);
      timeRemainingRef.current = promptDataRef.current.timeLimit;
      setShowPrompt(true);
    } else {
      return; // Kh√¥ng start n·∫øu kh√¥ng c√≥ prompt
    }
    
    setIsRecording(true);
    isRecordingRef.current = true;
    startTimeRef.current = Date.now();
    setHighlightedWords(new Set()); // Reset highlighted words
    setWebSpeechHighlights(new Set()); // Reset Web Speech highlights
    
    // ƒê·ª£i m·ªôt ch√∫t ƒë·ªÉ ƒë·∫£m b·∫£o prompt state ƒë√£ ƒë∆∞·ª£c update v√† refs ƒë∆∞·ª£c mount
    setTimeout(async () => {
      // Start Web Speech API for real-time recognition
      startSpeechRecognition();
      
      // Start audio recording directly using MediaRecorder
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaStreamRef.current = stream;
        audioChunksRef.current = [];
        
        const options = 
          typeof MediaRecorder !== "undefined" &&
          MediaRecorder.isTypeSupported &&
          MediaRecorder.isTypeSupported("audio/webm")
            ? { mimeType: "audio/webm" }
            : undefined;
        
        const mr = new MediaRecorder(stream, options);
        mediaRecorderRef.current = mr;
        
        mr.ondataavailable = (e) => {
          if (e.data && e.data.size > 0) {
            audioChunksRef.current.push(e.data);
          }
        };
        
        mr.onstop = () => {
          const blob = new Blob(audioChunksRef.current, { 
            type: audioChunksRef.current[0]?.type || "audio/webm" 
          });
          handleAudioRecorded(blob);
          
          // Stop all tracks
          if (mediaStreamRef.current) {
            mediaStreamRef.current.getTracks().forEach(track => track.stop());
            mediaStreamRef.current = null;
          }
        };
        
        mr.start();
      } catch (err) {
        console.error("‚ùå Error starting MediaRecorder:", err);
        // Fallback to AudioRecorder if available
        if (audioRecorderRef.current && audioRecorderRef.current.startRecording) {
          audioRecorderRef.current.startRecording();
        } else {
          console.error("‚ùå AudioRecorder also not available");
        }
      }
    }, 100);
  };

  // Helper function ƒë·ªÉ t√≠nh similarity gi·ªØa 2 t·ª´ (Levenshtein-like)
  const calculateSimilarity = (str1, str2) => {
    if (!str1 || !str2) return 0;
    
    const s1 = str1.toLowerCase();
    const s2 = str2.toLowerCase();
    
    // Exact match
    if (s1 === s2) return 1.0;
    
    // One contains the other
    if (s1.includes(s2) || s2.includes(s1)) {
      const longer = s1.length > s2.length ? s1 : s2;
      const shorter = s1.length > s2.length ? s2 : s1;
      return shorter.length / longer.length;
    }
    
    // Calculate character match ratio
    let matchCount = 0;
    const minLen = Math.min(s1.length, s2.length);
    const maxLen = Math.max(s1.length, s2.length);
    
    // Check prefix match
    for (let i = 0; i < minLen; i++) {
      if (s1[i] === s2[i]) matchCount++;
      else break;
    }
    
    // Check suffix match
    let suffixMatch = 0;
    for (let i = 1; i <= minLen; i++) {
      if (s1[s1.length - i] === s2[s2.length - i]) suffixMatch++;
      else break;
    }
    
    // Use the better match (prefix or suffix)
    const bestMatch = Math.max(matchCount, suffixMatch);
    return bestMatch / maxLen;
  };

  const startSpeechRecognition = () => {
    // Check if browser supports Web Speech API
    if (!("webkitSpeechRecognition" in window) && !("SpeechRecognition" in window)) {
      console.warn("‚ö†Ô∏è Web Speech API not supported");
      return;
    }

    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    const recognition = new SpeechRecognition();
    
    recognition.continuous = true;
    recognition.interimResults = true;
    recognition.lang = "en-US";

    recognition.onresult = (event) => {
      // S·ª≠ d·ª•ng prompt t·ª´ ref ho·∫∑c state
      const currentPrompt = prompt || promptDataRef.current?.prompt || "";
      
      if (!currentPrompt) {
        console.log("‚ùå No prompt available for matching");
        return;
      }
      
      // L·∫•y to√†n b·ªô transcript t·ª´ ƒë·∫ßu ƒë·∫øn hi·ªán t·∫°i (t√≠ch l≈©y)
      let fullTranscript = "";
      for (let i = 0; i < event.results.length; i++) {
        fullTranscript += event.results[i][0].transcript;
      }
      
      // L∆∞u Web Speech transcript
      setWebSpeechTranscript(fullTranscript);
      
      // Chuy·ªÉn transcript v√† prompt th√†nh lowercase ƒë·ªÉ so s√°nh
      const transcriptLower = fullTranscript.toLowerCase().trim();
      const transcriptWords = transcriptLower.split(/\s+/).map(w => w.replace(/[.,!?;:]/g, ""));
      const promptWords = currentPrompt.toLowerCase().split(/\s+/).map(w => w.replace(/[.,!?;:]/g, ""));
      
      // T√¨m c√°c t·ª´ ƒë√£ ƒë∆∞·ª£c n√≥i - so s√°nh theo th·ª© t·ª± v√† similarity
      const newHighlightedWords = new Set();
      const newWebSpeechHighlights = new Set(); // L∆∞u indices c·ªßa t·ª´ ƒë√£ match
      
      let transcriptWordIndex = 0;
      
      console.log(`üé§ Transcript: "${transcriptLower}"`);
      console.log(`üìù Prompt words: [${promptWords.join(', ')}]`);
      
      promptWords.forEach((promptWord, promptIdx) => {
        // T√¨m t·ª´ trong transcript b·∫Øt ƒë·∫ßu t·ª´ v·ªã tr√≠ hi·ªán t·∫°i
        for (let i = transcriptWordIndex; i < transcriptWords.length; i++) {
          const transcriptWord = transcriptWords[i];
          
          // ƒê∆°n gi·∫£n h√≥a logic matching: exact match ho·∫∑c partial match
          const isMatch = 
            transcriptWord === promptWord || // Exact match
            transcriptWord.includes(promptWord) || // Transcript ch·ª©a prompt
            (promptWord.includes(transcriptWord) && transcriptWord.length >= 3); // Prompt ch·ª©a transcript (transcript ƒë·ªß d√†i)
          
          if (isMatch) {
            newHighlightedWords.add(promptIdx);
            newWebSpeechHighlights.add(promptIdx); // L∆∞u cho backend
            transcriptWordIndex = i + 1; // Di chuy·ªÉn pointer
            break;
          }
        }
      });
      
      // C·∫≠p nh·∫≠t highlighted words cho UI
      setHighlightedWords(newHighlightedWords);
      setWebSpeechHighlights(newWebSpeechHighlights);
      
      // T·ª± ƒë·ªông chuy·ªÉn v√≤ng n·∫øu ƒë√£ ƒë·ªçc ƒë√∫ng h·∫øt t·∫•t c·∫£ t·ª´
      if (newHighlightedWords.size === promptWords.length && isRecordingRef.current) {
        console.log(`üöÄ Auto-submit triggered! All ${promptWords.length} words matched.`);
        // ƒê√°nh d·∫•u auto-submit ƒë·ªÉ handleAudioRecorded x·ª≠ l√Ω submit
        finishEarlyRef.current = true;
        // Stop recording ngay l·∫≠p t·ª©c
        stopRecording();
      }
    };

    recognition.onerror = (event) => {
      // Ignore "aborted" errors - x·∫£y ra khi stop() ƒë∆∞·ª£c g·ªçi
      if (event.error === 'aborted') {
        return;
      }
      console.error("Speech recognition error:", event.error);
      
      // Ch·ªâ restart n·∫øu kh√¥ng ph·∫£i l·ªói aborted v√† v·∫´n ƒëang recording
      if (event.error !== 'aborted' && isRecordingRef.current && recognitionRef.current === recognition) {
        setTimeout(() => {
          if (isRecordingRef.current && recognitionRef.current === recognition) {
            try {
              recognition.start();
            } catch (e) {
              // Ignore errors when restarting
            }
          }
        }, 500);
      }
    };

    recognition.onend = () => {
      // T·ª± ƒë·ªông restart n·∫øu v·∫´n ƒëang recording v√† kh√¥ng b·ªã abort
      if (isRecordingRef.current && recognitionRef.current === recognition) {
        setTimeout(() => {
          if (isRecordingRef.current && recognitionRef.current === recognition) {
            try {
              recognition.start();
            } catch (e) {
              // Ignore errors when restarting (c√≥ th·ªÉ b·ªã aborted)
              if (e.name !== 'InvalidStateError' && !e.message?.includes('abort')) {
                console.warn("Speech recognition restart error:", e);
              }
            }
          }
        }, 100);
      }
    };

    // L∆∞u recognition v√†o ref ƒë·ªÉ c√≥ th·ªÉ stop sau
    recognitionRef.current = recognition;
    
    try {
      recognition.start();
    } catch (err) {
      console.error("‚ùå Failed to start speech recognition:", err);
    }
  };

  const stopRecording = () => {
    setIsRecording(false);
    isRecordingRef.current = false;
    if (timerRef.current) {
      clearInterval(timerRef.current);
      timerRef.current = null;
    }
    
    // Stop speech recognition
    if (recognitionRef.current) {
      try {
        // Abort thay v√¨ stop ƒë·ªÉ tr√°nh l·ªói
        if (recognitionRef.current.abort) {
          recognitionRef.current.abort();
        } else {
          recognitionRef.current.stop();
        }
      } catch (e) {
        // Ignore errors (c√≥ th·ªÉ ƒë√£ b·ªã stop r·ªìi)
      }
      recognitionRef.current = null;
    }
    
    // Stop MediaRecorder directly
    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== "inactive") {
      mediaRecorderRef.current.stop();
    }
    
    // Fallback to AudioRecorder if available
    if (audioRecorderRef.current && audioRecorderRef.current.stopRecording) {
      audioRecorderRef.current.stopRecording();
    }
    
    // Stop media stream tracks
    if (mediaStreamRef.current) {
      mediaStreamRef.current.getTracks().forEach(track => track.stop());
      mediaStreamRef.current = null;
    }
  };

  const finishEarlyRef = useRef(false);

  const handleAudioRecorded = (blob) => {
    setAudioBlob(blob);
    
    // N·∫øu ƒëang trong qu√° tr√¨nh finish early (b·∫•m n√∫t ho·∫∑c auto-submit), submit ngay
    if (finishEarlyRef.current) {
      finishEarlyRef.current = false;
      stopRecording();
      // ƒê·ª£i m·ªôt ch√∫t ƒë·ªÉ ƒë·∫£m b·∫£o audio ƒë√£ ƒë∆∞·ª£c t·∫°o ho√†n to√†n
      setTimeout(() => {
        handleSubmit(blob);
      }, 500);
    } else {
      // Kh√¥ng c·∫ßn ki·ªÉm tra highlight n·ªØa - ch·ªâ d·ª´ng recording
      stopRecording();
    }
  };

  const handleFinishEarly = () => {
    if (isRecording) {
      // ƒê√°nh d·∫•u l√† mu·ªën finish early
      finishEarlyRef.current = true;
      
      // D·ª´ng AudioRecorder tr∆∞·ªõc
      if (audioRecorderRef.current && audioRecorderRef.current.stopRecording) {
        audioRecorderRef.current.stopRecording();
      }
      
      // D·ª´ng ghi √¢m s·ªõm
      stopRecording();
      
      // N·∫øu kh√¥ng c√≥ audioRecorderRef, th·ª≠ submit v·ªõi audioBlob hi·ªán t·∫°i ho·∫∑c ƒë·ª£i
      if (!audioRecorderRef.current && audioBlob) {
        setTimeout(() => {
          handleSubmit(audioBlob);
        }, 500);
      }
    } else if (audioBlob) {
      // N·∫øu ƒë√£ c√≥ audio, submit ngay
      handleSubmit(audioBlob);
    }
  };

  const handleSubmit = async (blob = null) => {
    const audio = blob || audioBlob;
    if (!audio) {
      alert("Vui l√≤ng ghi √¢m tr∆∞·ªõc khi n·ªôp b√†i");
      return;
    }

    if (submitting) {
      return; // Tr√°nh submit nhi·ªÅu l·∫ßn
    }

    setSubmitting(true);
    const timeTaken = startTimeRef.current
      ? Math.floor((Date.now() - startTimeRef.current) / 1000)
      : timeLimit - timeRemaining;

    try {
      // G·ª≠i audio k√®m prompt ƒë·ªÉ l∆∞u v√†o database
      const formData = new FormData();
      formData.append("audio", audio);
      formData.append("time_taken", timeTaken);
      formData.append("round_number", roundNumber);
      formData.append("prompt", prompt || promptDataRef.current?.prompt || ""); // QUAN TR·ªåNG: G·ª≠i prompt ƒë·ªÉ l∆∞u v√†o DB
      formData.append("web_speech_transcript", webSpeechTranscript); // G·ª≠i Web Speech transcript
      formData.append("web_speech_highlights", JSON.stringify(Array.from(webSpeechHighlights))); // G·ª≠i highlights t·ª´ Web Speech

      const res = await api.post(
        `/learners/speaking-practice/sessions/${sessionId}/rounds`,
        formData,
        { headers: { "Content-Type": "multipart/form-data" } }
      );

      const roundId = res.data.round_id;
      
      // Fetch analysis ƒë·ªÉ l·∫•y missing words v√† highlight
      let missingWordsList = [];
      try {
        const analysisRes = await api.get(
          `/learners/speaking-practice/sessions/${sessionId}/rounds/${roundId}/analysis`
        );
        
        if (analysisRes.data && analysisRes.data.analysis) {
          const analysis = typeof analysisRes.data.analysis === 'string' 
            ? JSON.parse(analysisRes.data.analysis) 
            : analysisRes.data.analysis;
          
          missingWordsList = analysis.missing_words || [];
          if (missingWordsList.length > 0) {
            // T·∫°o Set t·ª´ missing words ƒë·ªÉ highlight
            const promptWords = (prompt || promptDataRef.current?.prompt || "").toLowerCase().split(/\s+/);
            const missingSet = new Set();
            
            promptWords.forEach((word, idx) => {
              const cleanWord = word.replace(/[.,!?;:]/g, "");
              if (missingWordsList.some(mw => mw.toLowerCase().replace(/[.,!?;:]/g, "") === cleanWord)) {
                missingSet.add(idx);
              }
            });
            
            setMissingWords(missingSet);
          }
        }
      } catch (err) {
        console.warn("Failed to fetch analysis for missing words:", err);
      }
      
      // Kh√¥ng ƒë·ª£i analysis, chuy·ªÉn v√≤ng ngay
      setSubmitting(false);
      
      const roundData = {
        audioBlob: audio,
        timeTaken,
        prompt: prompt || promptDataRef.current?.prompt || "",
        round_id: roundId,
        missing_words: missingWordsList // L∆∞u missing_words t·ª´ analysis
      };
      
      // Chuy·ªÉn v√≤ng ngay
      if (onSave && typeof onSave === 'function') {
        onSave(roundData);
      }
    } catch (err) {
      console.error("‚ùå Error submitting round:", err);
      alert("C√≥ l·ªói x·∫£y ra. Vui l√≤ng th·ª≠ l·∫°i.");
      setSubmitting(false);
    }
  };


  const fetchWordDefinition = async (word) => {
    // Ki·ªÉm tra cache tr∆∞·ªõc
    if (wordDefinitionsCache[word]) {
      return wordDefinitionsCache[word];
    }

    // N·∫øu ƒëang loading, kh√¥ng fetch l·∫°i
    if (loadingWords[word]) {
      return null;
    }

    try {
      setLoadingWords(prev => ({ ...prev, [word]: true }));
      const res = await api.get(`/learners/dictionary/${encodeURIComponent(word)}`);
      const definition = res.data;
      
      // L∆∞u v√†o cache (state v√† localStorage)
      const newCache = {
        ...wordDefinitionsCache,
        [word]: definition
      };
      setWordDefinitionsCache(newCache);
      
      // L∆∞u v√†o localStorage (ch·ªâ l∆∞u 100 t·ª´ g·∫ßn nh·∫•t ƒë·ªÉ tr√°nh qu√° l·ªõn)
      try {
        const cacheEntries = Object.entries(newCache);
        const limitedCache = cacheEntries.slice(-100).reduce((acc, [key, value]) => {
          acc[key] = value;
          return acc;
        }, {});
        localStorage.setItem('wordDefinitionsCache', JSON.stringify(limitedCache));
      } catch (err) {
        console.warn("Could not save to localStorage:", err);
      }
      
      return definition;
    } catch (err) {
      console.error("‚ùå Error fetching word definition:", err);
      return null;
    } finally {
      setLoadingWords(prev => ({ ...prev, [word]: false }));
    }
  };

  // Pre-load t·∫•t c·∫£ t·ª´ trong prompt ƒë·ªÉ cache s·∫µn
  const preloadWordDefinitions = async (promptText) => {
    if (!promptText || preloadingWords) return;
    
    setPreloadingWords(true);
    
    // Extract unique words
    const words = promptText
      .toLowerCase()
      .split(/\s+/)
      .map((w) => w.replace(/[.,!?;:]/g, ""))
      .filter((w) => w.length > 0)
      .filter((w, i, arr) => arr.indexOf(w) === i); // Remove duplicates
    
    // Pre-fetch t·∫•t c·∫£ t·ª´ song song (batch 10 t·ª´ m·ªôt l√∫c ƒë·ªÉ nhanh h∆°n)
    const batchSize = 10;
    for (let i = 0; i < words.length; i += batchSize) {
      const batch = words.slice(i, i + batchSize);
      
      // Fetch song song t·∫•t c·∫£ t·ª´ trong batch
      const fetchPromises = batch
        .filter(word => !wordDefinitionsCache[word] && !loadingWords[word])
        .map(word => fetchWordDefinition(word).catch(err => {
          console.warn(`Failed to preload definition for ${word}:`, err);
          return null;
        }));
      
      // ƒê·ª£i batch n√†y ho√†n th√†nh tr∆∞·ªõc khi chuy·ªÉn batch ti·∫øp theo
      await Promise.all(fetchPromises);
      
      // Kh√¥ng c·∫ßn delay gi·ªØa c√°c batch v√¨ ƒë√£ ƒë·ª£i batch tr∆∞·ªõc ho√†n th√†nh
    }
    
    setPreloadingWords(false);
  };

  // Ph√°t √¢m t·ª´ khi click
  const speakWord = (word) => {
    // D·ª´ng b·∫•t k·ª≥ ph√°t √¢m n√†o ƒëang ch·∫°y
    window.speechSynthesis.cancel();
    
    const utterance = new SpeechSynthesisUtterance(word);
    utterance.lang = 'en-US';
    utterance.rate = 0.8; // Ch·∫≠m h∆°n m·ªôt ch√∫t ƒë·ªÉ d·ªÖ nghe
    utterance.pitch = 1;
    utterance.volume = 1;
    
    window.speechSynthesis.speak(utterance);
  };

  const handleWordClick = async (word, event) => {
    // Ph√°t √¢m t·ª´ ngay khi click
    speakWord(word);
    
    // Toggle tooltip: n·∫øu ƒëang m·ªü t·ª´ n√†y th√¨ ƒë√≥ng, n·∫øu kh√¥ng th√¨ m·ªü
    if (openWordTooltip === word) {
      setOpenWordTooltip(null);
      setWordTooltip(null);
      return;
    }

    // Ki·ªÉm tra cache tr∆∞·ªõc
    let definition = wordDefinitionsCache[word];
    
    if (!definition) {
      // Fetch n·∫øu ch∆∞a c√≥ trong cache
      definition = await fetchWordDefinition(word);
    }

    if (definition) {
      setWordTooltip({ word, ...definition });
      setOpenWordTooltip(word);
    } else {
      // N·∫øu ƒëang loading, ƒë·ª£i m·ªôt ch√∫t r·ªìi th·ª≠ l·∫°i
      setTimeout(async () => {
        const def = await fetchWordDefinition(word);
        if (def) {
          setWordTooltip({ word, ...def });
          setOpenWordTooltip(word);
        }
      }, 100);
    }
  };

  const formatTime = (seconds) => {
    const m = Math.floor(seconds / 60);
    const s = seconds % 60;
    return `${m}:${s.toString().padStart(2, "0")}`;
  };

  // B·ªè countdown overlay - kh√¥ng c·∫ßn n·ªØa v√¨ t·ª± ƒë·ªông b·∫Øt ƒë·∫ßu

  // M√†n h√¨nh ch√≠nh - ghi √¢m
  return (
    <div className="speaking-round">
      <div className="round-header">
        <h3>V√≤ng {roundNumber}/10</h3>
        <button className="btn-cancel" onClick={onCancel}>
          H·ªßy
        </button>
      </div>

      <div className="round-content">
        {showPrompt ? (
          <>
            <div className="prompt-section" style={{ position: "relative" }}>
              <div style={{ display: "flex", justifyContent: "space-between", alignItems: "center", marginBottom: "16px" }}>
                <h4 style={{ margin: 0 }}>ƒê·ªçc ƒëo·∫°n vƒÉn sau:</h4>
                {/* Circular Progress Indicator - V√≤ng tr√≤n nh·ªè ·ªü g√≥c tr√™n ph·∫£i */}
                {isRecording && (
                  <div 
                    key={progressAnimationKey}
                    style={{
                      width: "48px",
                      height: "48px",
                      position: "relative",
                      flexShrink: 0
                    }}
                  >
                    <svg 
                      width="48" 
                      height="48" 
                      style={{ transform: "rotate(-90deg)" }}
                    >
                      {/* Background circle */}
                      <circle
                        cx="24"
                        cy="24"
                        r="20"
                        fill="none"
                        stroke="#e5e7eb"
                        strokeWidth="4"
                      />
                      {/* Progress circle */}
                      <circle
                        cx="24"
                        cy="24"
                        r="20"
                        fill="none"
                        stroke="#10b981"
                        strokeWidth="4"
                        strokeLinecap="round"
                        strokeDasharray={`${2 * Math.PI * 20}`}
                        strokeDashoffset={`${2 * Math.PI * 20}`}
                        style={{
                          animation: `progressCircleComplete ${timeLimit}s linear forwards`
                        }}
                      />
                    </svg>
                    {/* Time remaining text */}
                    <div style={{
                      position: "absolute",
                      top: "50%",
                      left: "50%",
                      transform: "translate(-50%, -50%)",
                      fontSize: "12px",
                      fontWeight: "bold",
                      color: "#10b981"
                    }}>
                      {timeRemaining}
                    </div>
                  </div>
                )}
              </div>
              <div className="prompt-text" style={{ 
                position: "relative", 
                zIndex: 2, 
                padding: "24px",
                background: "white",
                borderRadius: "8px",
                border: "1px solid #e5e7eb",
                boxShadow: "0 2px 8px rgba(0, 0, 0, 0.08)",
                fontSize: "18px",
                lineHeight: "1.8",
                color: "#333"
              }}>
                {(() => {
                  // T√°ch prompt th√†nh words v√† spaces ƒë·ªÉ map ƒë√∫ng index
                  const parts = prompt.split(/(\s+)/);
                  let wordIndex = 0; // Index c·ªßa t·ª´ trong prompt (b·ªè qua spaces)
                  
                  return parts.map((part, idx) => {
                    // N·∫øu l√† kho·∫£ng tr·∫Øng, render tr·ª±c ti·∫øp
                    if (/^\s+$/.test(part)) {
                      return <span key={idx}>{part}</span>;
                    }
                    
                    // ƒê√¢y l√† m·ªôt t·ª´
                    const currentWordIndex = wordIndex;
                    wordIndex++; // TƒÉng index cho t·ª´ ti·∫øp theo
                    
                    const cleanWord = part.replace(/[.,!?;:]/g, "").toLowerCase();
                    const isHighlighted = highlightedWords.has(currentWordIndex);
                    const isMissing = missingWords.has(currentWordIndex);
                  
                  return (
                    <span
                      key={idx}
                      onClick={(e) => {
                        // Ch·ªâ ph√°t √¢m, kh√¥ng hi·ªÉn th·ªã tooltip khi ƒëang luy·ªán n√≥i
                        speakWord(cleanWord);
                      }}
                      style={{ 
                        cursor: "pointer", 
                        position: "relative", 
                        display: "inline-block",
                        padding: "2px 4px",
                        borderRadius: "3px",
                        transition: "all 0.2s",
                        fontWeight: isHighlighted ? "bold" : "normal",
                        backgroundColor: isHighlighted ? "#d1fae5" : (isMissing ? "#fee2e2" : "transparent"),
                        color: isHighlighted ? "#065f46" : (isMissing ? "#991b1b" : "#333")
                      }}
                      onMouseEnter={(e) => {
                        if (!isHighlighted && !isMissing) {
                          e.target.style.backgroundColor = "#f3f4f6";
                        }
                      }}
                      onMouseLeave={(e) => {
                        if (!isHighlighted && !isMissing) {
                          e.target.style.backgroundColor = "transparent";
                        }
                      }}
                    >
                      {part}
                    </span>
                  );
                  });
                })()}
                </div>
            </div>

            <div className="recording-section">
              <div className="mic-container">
                <div className={`mic-icon ${isRecording ? "recording" : ""}`}>
                  <FaMicrophone size={64} />
                </div>
                {isRecording && (
                  <div className="recording-waves">
                    <span></span>
                    <span></span>
                    <span></span>
                  </div>
                )}
              </div>
              
              {isRecording && (
                <div className="recording-active">
                  <div className="recording-indicator">
                    <span className="pulse"></span>
                    ƒêang ghi √¢m...
                  </div>
                  <div style={{ marginTop: 12, fontSize: 14, color: "#666" }}>
                    ƒê·ªçc to v√† r√µ r√†ng ƒëo·∫°n vƒÉn tr√™n
                  </div>
                </div>
              )}

              {audioBlob && !isRecording && !submitting && (
                <div className="audio-complete">
                  <p style={{ marginBottom: 12, color: "#10b981" }}>
                    ‚úÖ ƒê√£ ghi √¢m xong. ƒêang l∆∞u...
                  </p>
                </div>
              )}

              {submitting && (
                <div className="submitting-indicator">
                  <p>ƒêang l∆∞u...</p>
                </div>
              )}
            </div>
          </>
        ) : (
          <div className="recording-section">
            <div className="recording-controls">
              {loadingPrompt ? (
                <p style={{ textAlign: "center", color: "#666" }}>
                  ƒêang t·∫£i ƒë·ªÅ b√†i...
                </p>
              ) : promptError ? (
                <div style={{ textAlign: "center" }}>
                  <p style={{ color: "#ef4444", marginBottom: 12 }}>
                    ‚ùå {promptError}
                  </p>
                  <button
                    onClick={fetchPrompt}
                    style={{
                      padding: "8px 16px",
                      background: "#10b981",
                      color: "white",
                      border: "none",
                      borderRadius: 4,
                      cursor: "pointer"
                    }}
                  >
                    Th·ª≠ l·∫°i
                  </button>
                </div>
              ) : (
                <p style={{ textAlign: "center", color: "#666" }}>
                  ƒêang t·∫£i ƒë·ªÅ b√†i...
                </p>
              )}
            </div>
          </div>
        )}
      </div>
    </div>
  );
}
