// Learner Service - Queue Handlers
import { registerProcessor } from "./utils/queue.js";
import * as learnerService from "./services/learnerService.js";
// TODO: Replace with API calls to AI Service
// import * as learnerAiService from "./services/learnerAiService.js";
import { runWhisperX } from "./utils/whisperxRunner.js";
import path from "path";
import fs from "fs";
import { fileURLToPath } from "url";
import pool from "./config/db.js";

/**
 * T√¨m project root (ƒëi l√™n t·ª´ learner-service/src ƒë·∫øn backend)
 */
function getProjectRoot() {
  const __filename = fileURLToPath(import.meta.url);
  const __dirname = path.dirname(__filename);
  // __dirname = backend/services/learner-service/src
  // Go up 3 levels: src -> learner-service -> services -> backend
  return path.resolve(__dirname, "..", "..", "..");
}

function audioUrlToLocalPath(audioUrl) {
  const m = String(audioUrl || "").match(/\/uploads\/(.+)$/);
  if (!m) return null;
  const filename = m[1];
  // T√¨m file ·ªü backend/uploads/
  const backendDir = getProjectRoot();
  return path.resolve(backendDir, "uploads", filename);
}

// Queue handler ƒë·ªÉ x·ª≠ l√Ω submission analysis
registerProcessor("analyzeSubmission", async (job) => {
  const { submissionId } = job.data;
  console.log("üîÑ Processing analyzeSubmission job:", submissionId);

  const sub = await learnerService.getSubmissionById(submissionId);
  if (!sub) {
    console.warn("‚ö†Ô∏è Submission not found:", submissionId);
    return;
  }

  let transcript = sub.transcript ?? null;

  // N·∫øu ch∆∞a c√≥ transcript th√¨ ch·∫°y WhisperX
  if (!transcript) {
    if (!sub.audio_url) {
      console.warn("‚ö†Ô∏è No audio_url to transcribe:", submissionId);
      await learnerService.updateSubmissionStatus(submissionId, "failed");
      return;
    }

    const localPath = audioUrlToLocalPath(sub.audio_url);
    if (!localPath || !fs.existsSync(localPath)) {
      console.error("‚ùå Local audio file not found:", localPath);
      await learnerService.updateSubmissionStatus(submissionId, "failed");
      return;
    }

    try {
      console.log("üîä Transcribing audio:", localPath);
      const { json: transcriptJson } = await runWhisperX(localPath, {
        model: "base",
        computeType: "float32",
        timeoutMs: 3 * 60 * 1000,
      });

      if (transcriptJson) {
        await learnerService.updateSubmissionTranscript(submissionId, transcriptJson);
        transcript = transcriptJson;

        if (Array.isArray(transcriptJson.segments)) {
          await learnerService.updateSubmissionSegments(submissionId, transcriptJson.segments);
        }

        console.log("üìù Transcript + segments saved:", submissionId);
      } else {
        console.warn("‚ö†Ô∏è Empty transcript JSON:", submissionId);
        await learnerService.updateSubmissionStatus(submissionId, "pending_transcription");
        return;
      }
    } catch (err) {
      console.error("‚ùå Transcription failed:", submissionId, err);
      await learnerService.updateSubmissionStatus(submissionId, "failed");
      return;
    }
  }

  // Ph√¢n t√≠ch transcript b·∫±ng AI Service
  try {
    console.log("üß† Analyzing transcript:", submissionId);

    const challenge = await learnerService.getChallengeById(sub.challenge_id);

    // G·ªçi qua API Gateway thay v√¨ tr·ª±c ti·∫øp ƒë·∫øn AI Service
    // Extract transcript text - handle both object and string formats
    let transcriptText = "";
    if (typeof transcript === "string") {
      transcriptText = transcript;
    } else if (transcript && typeof transcript === "object") {
      transcriptText = transcript.text || (transcript.segments || []).map(s => s.text || "").join(" ") || "";
    }
    
    if (!transcriptText || transcriptText.trim().length === 0) {
      console.error("‚ùå Empty transcript text:", submissionId);
      await learnerService.updateSubmissionStatus(submissionId, "failed");
      return;
    }

    console.log(`[DEBUG] Sending transcript to AI Service (length: ${transcriptText.length}):`, transcriptText.substring(0, 100) + "...");
    
    const response = await fetch(`http://localhost:${process.env.API_GATEWAY_PORT || 4000}/api/ai/learner/analyze-transcript`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        transcript: transcriptText,
        options: {
          runTopicDetection: true,
          challenge,
          sampleTranscripts: []
        }
      })
    });

    if (!response.ok) {
      const errorText = await response.text().catch(() => "");
      console.error(`‚ùå AI Service error ${response.status}:`, errorText);
      throw new Error(`AI Service error: ${response.status} - ${errorText}`);
    }

    const analysis = await response.json();

    if (!analysis || typeof analysis !== "object") {
      console.error("‚ùå Invalid analysis result:", submissionId, analysis);
      await learnerService.updateSubmissionStatus(submissionId, "failed");
      return;
    }

    await learnerService.updateSubmissionAnalysis(submissionId, { ...analysis, transcript });
    await learnerService.updateSubmissionStatus(submissionId, "completed");
    console.log("‚úÖ AI analysis saved:", submissionId);
  } catch (err) {
    console.error("‚ùå AI analysis failed:", submissionId, err);
    await learnerService.updateSubmissionStatus(submissionId, "failed");
  }
});

// Queue handler ƒë·ªÉ x·ª≠ l√Ω speaking round (transcription + AI analysis)
registerProcessor("processSpeakingRound", async (job) => {
  console.log("üöÄ QUEUE HANDLER STARTED for speaking round");
  const { roundId, sessionId, audioUrl, prompt, level, time_taken, webSpeechTranscript, webSpeechHighlights: originalWebSpeechHighlights } = job.data;
  let webSpeechHighlights = originalWebSpeechHighlights; // Mutable copy
  console.log("üîÑ Processing speaking round:", roundId);
  console.log("üé§ Web Speech data received:", {
    hasTranscript: !!webSpeechTranscript,
    highlightsLength: webSpeechHighlights ? webSpeechHighlights.length : 0,
    highlights: webSpeechHighlights
  });

  try {
    // Transcribe audio
    const backendDir = getProjectRoot();
    const localPath = audioUrl.startsWith("/uploads/")
      ? path.join(backendDir, audioUrl)
      : audioUrl;

    let transcript = null;
    if (fs.existsSync(localPath)) {
      console.log(`üìÅ Audio file exists: ${localPath}`);
      try {
        console.log(`üéôÔ∏è Starting WhisperX transcription with model medium...`);
        const { json: transcriptJson } = await runWhisperX(localPath, {
          model: "medium",
          language: "en",
          computeType: "float32"
        });
        transcript = transcriptJson;
        console.log(`‚úÖ WhisperX transcription completed: ${transcript?.text?.substring(0, 100)}...`);
      } catch (err) {
        console.error("‚ùå Transcription error:", err.message);
        console.error("‚ùå Error stack:", err.stack);
        console.error("‚ùå Trying with base model...");
        // Fallback to base model
        try {
          const { json: transcriptJson } = await runWhisperX(localPath, {
            model: "base",
            computeType: "float32"
          });
          transcript = transcriptJson;
          console.log(`‚úÖ WhisperX base model transcription completed: ${transcript?.text?.substring(0, 100)}...`);
        } catch (err2) {
          console.error("‚ùå Base model also failed:", err2.message);
          // Kh√¥ng return, ti·∫øp t·ª•c v·ªõi transcript = null
        }
      }
    } else {
      console.error(`‚ùå Audio file not found: ${localPath}`);
    }

    // N·∫øu kh√¥ng c√≥ Web Speech highlights, t·∫°o t·ª´ WhisperX transcript
    if ((!webSpeechHighlights || !Array.isArray(webSpeechHighlights) || webSpeechHighlights.length === 0) && transcript && transcript.text) {
      console.log(`üîÑ Generating highlights from WhisperX transcript...`);
      const transcriptText = transcript.text;
      const transcriptWords = transcriptText.toLowerCase().split(/\s+/).filter(w => w.length > 0);
      const expectedWords = prompt.toLowerCase().split(/\s+/).map(w => w.replace(/[.,!?;:]/g, "")).filter(w => w.length > 0);
      
      // T·∫°o highlights b·∫±ng c√°ch match transcript words v·ªõi expected words
      const generatedHighlights = [];
      expectedWords.forEach((expectedWord, idx) => {
        const cleanExpected = expectedWord.replace(/[.,!?;:]/g, "").trim();
        if (!cleanExpected) return;
        
        const matched = transcriptWords.some(transcriptWord => {
          const cleanTranscript = transcriptWord.replace(/[.,!?;:]/g, "").trim();
          if (!cleanTranscript) return false;
          if (cleanTranscript === cleanExpected) return true;
          if (cleanTranscript.length >= cleanExpected.length && cleanTranscript.includes(cleanExpected)) return true;
          if (cleanExpected.length >= cleanTranscript.length && cleanExpected.includes(cleanTranscript) && cleanTranscript.length >= 3) return true;
          return false;
        });
        
        if (matched) {
          generatedHighlights.push(idx);
        }
      });
      
      webSpeechHighlights = generatedHighlights;
      console.log(`‚úÖ Generated ${generatedHighlights.length} highlights from WhisperX:`, generatedHighlights);
    }

    // Analyze v·ªõi AI Service
    let analysis = null;
    let score = 0;
    let feedback = "";
    let errors = [];
    let correctedText = "";

    // ∆ØU TI√äN 1: N·∫øu c√≥ Web Speech highlights, d√πng ch√∫ng ƒë·ªÉ t√≠nh ƒëi·ªÉm ngay
    if (webSpeechHighlights && Array.isArray(webSpeechHighlights) && webSpeechHighlights.length > 0) {
      console.log(`üéØ Using Web Speech highlights for scoring: ${webSpeechHighlights.length} matched words`);
      console.log(`üîç Highlights data:`, webSpeechHighlights);
      console.log(`üîç Highlights types:`, webSpeechHighlights.map(h => typeof h));
      
      // Convert to numbers if they're strings
      const numericHighlights = webSpeechHighlights.map(h => typeof h === 'string' ? parseInt(h, 10) : h);
      console.log(`üî¢ Numeric highlights:`, numericHighlights);
      
      const expectedWords = prompt.toLowerCase().split(/\s+/).map(w => w.replace(/[.,!?;:]/g, "")).filter(w => w.length > 0);
      const matchedWords = expectedWords.filter((_, idx) => numericHighlights.includes(idx));
      const missingWords = expectedWords.filter((_, idx) => !numericHighlights.includes(idx));
      
      // T√≠nh ƒëi·ªÉm d·ª±a tr√™n highlights t·ª´ Web Speech
      const scoreFromHighlights = Math.round((matchedWords.length / expectedWords.length) * 100);
      
      score = scoreFromHighlights;
      feedback = scoreFromHighlights > 0 
        ? `B·∫°n ƒë√£ n√≥i ƒë√∫ng ${matchedWords.length}/${expectedWords.length} t·ª´. ${missingWords.length > 0 ? `C·∫ßn c·∫£i thi·ªán: ${missingWords.slice(0, 5).join(", ")}` : "Tuy·ªát v·ªùi!"}`
        : "B·∫°n ch∆∞a n√≥i ƒë√∫ng t·ª´ n√†o. H√£y nghe l·∫°i v√† n√≥i theo prompt.";
      analysis = {
        score: scoreFromHighlights,
        feedback: feedback,
        missing_words: missingWords,
        errors: [],
        corrected_text: prompt
      };
      
      console.log(`‚úÖ Web Speech scoring: ${scoreFromHighlights}/100, matched=${matchedWords.length}/${expectedWords.length}`);
    } else if (webSpeechTranscript && webSpeechTranscript.trim()) {
      // Fallback: D√πng Web Speech transcript ƒë·ªÉ t√≠nh ƒëi·ªÉm
      console.log(`üé§ Using Web Speech transcript for scoring: "${webSpeechTranscript.substring(0, 100)}..."`);
      
      const transcriptWords = webSpeechTranscript.toLowerCase().split(/\s+/).filter(w => w.length > 0);
      const expectedWords = prompt.toLowerCase().split(/\s+/).map(w => w.replace(/[.,!?;:]/g, "")).filter(w => w.length > 0);
      
      // T√≠nh s·ªë t·ª´ match t·ª´ Web Speech transcript
      const matchedWords = expectedWords.filter(ew => {
        const cleanExpected = ew.replace(/[.,!?;:]/g, "").trim();
        if (!cleanExpected) return false;
        return transcriptWords.some(tw => {
          const cleanTranscript = tw.replace(/[.,!?;:]/g, "").trim();
          if (!cleanTranscript) return false;
          if (cleanTranscript === cleanExpected) return true;
          if (cleanTranscript.length >= cleanExpected.length && cleanTranscript.includes(cleanExpected)) return true;
          if (cleanExpected.length >= cleanTranscript.length && cleanExpected.includes(cleanTranscript) && cleanTranscript.length >= 3) return true;
          return false;
        });
      });
      
      // T√≠nh ƒëi·ªÉm d·ª±a tr√™n s·ªë t·ª´ ƒë√∫ng
      const scoreFromTranscript = Math.round((matchedWords.length / expectedWords.length) * 100);
      const missingWords = expectedWords.filter(ew => !matchedWords.includes(ew));
      
      score = scoreFromTranscript;
      feedback = scoreFromTranscript > 0 
        ? `B·∫°n ƒë√£ n√≥i ƒë√∫ng ${matchedWords.length}/${expectedWords.length} t·ª´. ${missingWords.length > 0 ? `C·∫ßn c·∫£i thi·ªán: ${missingWords.slice(0, 5).join(", ")}` : "Tuy·ªát v·ªùi!"}`
        : "Kh√¥ng th·ªÉ ph√¢n t√≠ch ch√≠nh x√°c. Vui l√≤ng th·ª≠ l·∫°i.";
      analysis = {
        score: scoreFromTranscript,
        feedback: feedback,
        missing_words: missingWords,
        errors: [],
        corrected_text: prompt
      };
      
      console.log(`‚úÖ Web Speech transcript scoring: ${scoreFromTranscript}/100, matched=${matchedWords.length}/${expectedWords.length}`);
    } else if (transcript) {
      const transcriptText = transcript.text || (transcript.segments || []).map(s => s.text || "").join(" ");

      try {
        // QUAN TR·ªåNG: D√πng analyzePronunciation tr·ª±c ti·∫øp thay v√¨ g·ªçi API
        // ƒê·ªÉ ƒë·∫£m b·∫£o logic t√≠nh ƒëi·ªÉm d·ª±a tr√™n s·ªë t·ª´ ƒë√∫ng ƒë∆∞·ª£c √°p d·ª•ng
        const { analyzePronunciation } = await import("./services/speakingPracticeService.js");
        
        // L·∫•y learner_id t·ª´ session
        const sessionInfo = await pool.query(
          `SELECT learner_id FROM speaking_practice_sessions WHERE id = $1`,
          [sessionId]
        );
        const learnerId = sessionInfo.rows[0]?.learner_id;
        
        analysis = await analyzePronunciation(transcriptText, prompt, level, roundId, sessionId, learnerId);
        score = Math.round(analysis.score || 0);
        feedback = analysis.feedback || "";
        errors = analysis.errors || [];
        correctedText = analysis.corrected_text || "";
        
        console.log(`‚úÖ WhisperX analyzed, score=${score}, missing_words=${analysis?.missing_words?.length || 0}`);
      } catch (err) {
        console.error("‚ùå AI analysis error in queue handler:", err);
        console.error("‚ùå Error stack:", err.stack);
        
        // Fallback cu·ªëi: T√≠nh ƒëi·ªÉm d·ª±a tr√™n transcript matching
        if (transcriptText && transcriptText.trim()) {
          const transcriptWords = transcriptText.toLowerCase().split(/\s+/).filter(w => w.length > 0);
          const expectedWords = prompt.toLowerCase().split(/\s+/).map(w => w.replace(/[.,!?;:]/g, "")).filter(w => w.length > 0);
          
          // T√≠nh s·ªë t·ª´ match
          const matchedWords = expectedWords.filter(ew => {
            const cleanExpected = ew.replace(/[.,!?;:]/g, "").trim();
            if (!cleanExpected) return false;
            return transcriptWords.some(tw => {
              const cleanTranscript = tw.replace(/[.,!?;:]/g, "").trim();
              if (!cleanTranscript) return false;
              if (cleanTranscript === cleanExpected) return true;
              if (cleanTranscript.length >= cleanExpected.length && cleanTranscript.includes(cleanExpected)) return true;
              if (cleanExpected.length >= cleanTranscript.length && cleanExpected.includes(cleanTranscript) && cleanTranscript.length >= 3) return true;
              return false;
            });
          });
          
          // T√≠nh ƒëi·ªÉm d·ª±a tr√™n s·ªë t·ª´ ƒë√∫ng
          const fallbackScore = matchedWords.length > 0 
            ? Math.round((matchedWords.length / expectedWords.length) * 100)
            : 0;
          
          const missingWords = expectedWords.filter(ew => !matchedWords.includes(ew));
          
          score = fallbackScore;
          feedback = fallbackScore > 0 
            ? `B·∫°n ƒë√£ n√≥i ƒë√∫ng ${matchedWords.length}/${expectedWords.length} t·ª´. ${missingWords.length > 0 ? `C·∫ßn c·∫£i thi·ªán: ${missingWords.slice(0, 5).join(", ")}` : "Tuy·ªát v·ªùi!"}`
            : "Kh√¥ng th·ªÉ ph√¢n t√≠ch ch√≠nh x√°c. Vui l√≤ng th·ª≠ l·∫°i.";
          analysis = {
            score: fallbackScore,
            feedback: feedback,
            missing_words: missingWords,
            errors: [],
            corrected_text: prompt
          };
          
          console.log(`‚ö†Ô∏è Using transcript fallback scoring: score=${fallbackScore}, matched=${matchedWords.length}/${expectedWords.length}`);
        } else {
          // Kh√¥ng c√≥ transcript
          feedback = "B·∫°n ch∆∞a n√≥i g√¨. H√£y th·ª≠ l·∫°i v√† n√≥i to, r√µ r√†ng.";
          score = 0;
          analysis = {
            score: 0,
            feedback: feedback,
            missing_words: prompt.toLowerCase().split(/\s+/).filter(w => w.length > 0),
            errors: [],
            corrected_text: prompt
          };
        }
      }
    } else {
      // Kh√¥ng c√≥ transcript t·ª´ WhisperX, ki·ªÉm tra Web Speech data
      if (webSpeechHighlights && Array.isArray(webSpeechHighlights) && webSpeechHighlights.length > 0) {
        console.log(`üéØ Using Web Speech highlights (no WhisperX transcript): ${webSpeechHighlights.length} matched words`);
        
        const expectedWords = prompt.toLowerCase().split(/\s+/).filter(w => w.length > 0);
        const matchedWords = expectedWords.filter((_, idx) => webSpeechHighlights.includes(idx));
        const missingWords = expectedWords.filter((_, idx) => !webSpeechHighlights.includes(idx));
        
        // T√≠nh ƒëi·ªÉm d·ª±a tr√™n highlights t·ª´ Web Speech
        const scoreFromHighlights = Math.round((matchedWords.length / expectedWords.length) * 100);
        
        score = scoreFromHighlights;
        feedback = scoreFromHighlights > 0 
          ? `B·∫°n ƒë√£ n√≥i ƒë√∫ng ${matchedWords.length}/${expectedWords.length} t·ª´. ${missingWords.length > 0 ? `C·∫ßn c·∫£i thi·ªán: ${missingWords.slice(0, 5).join(", ")}` : "Tuy·ªát v·ªùi!"}`
          : "B·∫°n ch∆∞a n√≥i ƒë√∫ng t·ª´ n√†o. H√£y nghe l·∫°i v√† n√≥i theo prompt.";
        analysis = {
          score: scoreFromHighlights,
          feedback: feedback,
          missing_words: missingWords,
          errors: [],
          corrected_text: prompt
        };
        
        console.log(`‚úÖ Web Speech scoring (no transcript): ${scoreFromHighlights}/100, matched=${matchedWords.length}/${expectedWords.length}`);
      } else if (webSpeechTranscript && webSpeechTranscript.trim()) {
        // Fallback: D√πng Web Speech transcript
        console.log(`üé§ Using Web Speech transcript (no WhisperX): "${webSpeechTranscript.substring(0, 100)}..."`);
        
        const transcriptWords = webSpeechTranscript.toLowerCase().split(/\s+/).filter(w => w.length > 0);
        const expectedWords = prompt.toLowerCase().split(/\s+/).filter(w => w.length > 0);
        
        const matchedWords = expectedWords.filter(ew => {
          const cleanExpected = ew.replace(/[.,!?;:]/g, "").trim();
          if (!cleanExpected) return false;
          return transcriptWords.some(tw => {
            const cleanTranscript = tw.replace(/[.,!?;:]/g, "").trim();
            if (!cleanTranscript) return false;
            if (cleanTranscript === cleanExpected) return true;
            if (cleanTranscript.length >= cleanExpected.length && cleanTranscript.includes(cleanExpected)) return true;
            if (cleanExpected.length >= cleanTranscript.length && cleanExpected.includes(cleanTranscript) && cleanTranscript.length >= 3) return true;
            return false;
          });
        });
        
        const scoreFromTranscript = Math.round((matchedWords.length / expectedWords.length) * 100);
        const missingWords = expectedWords.filter(ew => !matchedWords.includes(ew));
        
        score = scoreFromTranscript;
        feedback = scoreFromTranscript > 0 
          ? `B·∫°n ƒë√£ n√≥i ƒë√∫ng ${matchedWords.length}/${expectedWords.length} t·ª´. ${missingWords.length > 0 ? `C·∫ßn c·∫£i thi·ªán: ${missingWords.slice(0, 5).join(", ")}` : "Tuy·ªát v·ªùi!"}`
          : "Kh√¥ng th·ªÉ ph√¢n t√≠ch ch√≠nh x√°c. Vui l√≤ng th·ª≠ l·∫°i.";
        analysis = {
          score: scoreFromTranscript,
          feedback: feedback,
          missing_words: missingWords,
          errors: [],
          corrected_text: prompt
        };
        
        console.log(`‚úÖ Web Speech transcript scoring (no WhisperX): ${scoreFromTranscript}/100, matched=${matchedWords.length}/${expectedWords.length}`);
      } else {
        score = 0;
        feedback = "B·∫°n ch∆∞a n√≥i g√¨. H√£y th·ª≠ l·∫°i v√† n√≥i to, r√µ r√†ng.";
        analysis = {
          score: 0,
          feedback: feedback,
          missing_words: prompt.toLowerCase().split(/\s+/).filter(w => w.length > 0),
          errors: [],
          corrected_text: prompt
        };
      }
    }

    // Build word_analysis t·ª´ transcript
    let wordAnalysis = [];
    if (transcript && transcript.words && Array.isArray(transcript.words)) {
      wordAnalysis = transcript.words.map((w, idx) => ({
        word: w.text ?? w.word ?? "",
        start: typeof w.start === "number" ? w.start : null,
        end: typeof w.end === "number" ? w.end : null,
        confidence: typeof w.score === "number" ? w.score : w.confidence ?? null,
        wordIndex: idx
      }));
    }

    // C·∫≠p nh·∫≠t database v·ªõi k·∫øt qu·∫£ (bao g·ªìm missing_words ƒë·ªÉ highlight t·ª´ sai)
    console.log(`üìä Final score before DB update: ${score}, analysis score: ${analysis?.score}`);
    try {
      await pool.query(
        `UPDATE speaking_practice_rounds 
         SET transcript = $1, score = $2, analysis = $3
         WHERE id = $4`,
        [
          transcript ? JSON.stringify(transcript) : null,
          score,
          JSON.stringify({
            feedback,
            errors,
            corrected_text: correctedText || prompt,
            score,
            missing_words: analysis?.missing_words || [], // C√°c t·ª´ sai ƒë·ªÉ highlight
            word_analysis: wordAnalysis.length > 0 ? wordAnalysis : []
          }),
          roundId
        ]
      );
      console.log(`‚úÖ Queue handler: Updated round ${roundId} with score ${score}, missing_words=${analysis?.missing_words?.length || 0}`);
    } catch (dbErr) {
      console.error(`‚ùå Database update error in queue handler for round ${roundId}:`, dbErr);
    }

    console.log("‚úÖ Speaking round processed:", roundId);
  } catch (err) {
    console.error("‚ùå Process speaking round error:", err);
  }
});

